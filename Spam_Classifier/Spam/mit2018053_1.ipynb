{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"spam.csv\",encoding=\"latin-1\")\n",
    "df=df.iloc[:,0:2]\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        v1                                                 v2  LABEL\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...      1\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?      0\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...      0\n",
       "5570   ham  The guy did some bitching but I acted like i'd...      0\n",
       "5571   ham                         Rofl. Its true to its name      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LABEL']=df.v1.map({'ham':0,'spam':1})\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go jurong point, crazy.. avail bugi n great wo...\n",
      "1                             ok lar... joke wif u oni...\n",
      "2       free entri 2 wkli comp win fa cup final tkt 21...\n",
      "3               u dun say earli hor... u c alreadi say...\n",
      "4                   nah think goe usf, live around though\n",
      "5       freemsg hey darl 3 week' word back! i'd like f...\n",
      "6       even brother like speak me. treat like aid pat...\n",
      "7       per request 'mell mell (oru minnaminungint nur...\n",
      "8       winner!! valu network custom select receivea å...\n",
      "9       mobil 11 month more? u r entitl updat latest c...\n",
      "10      i'm gonna home soon want talk stuff anymor ton...\n",
      "11      six chanc win cash! 100 20,000 pound txt> csh1...\n",
      "12      urgent! 1 week free membership å£100,000 prize...\n",
      "13      i'v search right word thank breather. promis w...\n",
      "14                                     date sunday will!!\n",
      "15      xxxmobilemovieclub: use credit, click wap link...\n",
      "16                                oh k...i'm watch here:)\n",
      "17      eh u rememb 2 spell name... ye did. v naughti ...\n",
      "18              fine thatåõ way u feel. thatåõ way gota b\n",
      "19      england v macedonia - dont miss goals/team new...\n",
      "20                                    serious spell name?\n",
      "21                        iû÷m go tri 2 month ha ha joke\n",
      "22                  ì_ pay first lar... da stock comin...\n",
      "23      aft finish lunch go str lor. ard 3 smth lor. u...\n",
      "24                   ffffffffff. alright way meet sooner?\n",
      "25      forc eat slice. i'm realli hungri tho. sucks. ...\n",
      "26                                  lol alway convincing.\n",
      "27      catch bu ? fri egg ? make tea? eat mom' left d...\n",
      "28      i'm back &amp; we'r pack car now, i'll let kno...\n",
      "29           ahhh. work. vagu rememb that! feel like? lol\n",
      "                              ...                        \n",
      "5542                           armand say get ass epsilon\n",
      "5543                 u still havent got urself jacket ah?\n",
      "5544    i'm take derek &amp; taylor walmart, i'm back ...\n",
      "5545                               hi durban still number\n",
      "5546                        ic. lotta childporn car then.\n",
      "5547    contract mobil 11 mnths? latest motorola, noki...\n",
      "5548                                   no, tri weekend ;v\n",
      "5549    know, wot peopl wear. shirts, jumpers, hat, be...\n",
      "5550                           cool, time think get here?\n",
      "5551                    wen get spiritu deep. that' great\n",
      "5552    safe trip nigeria. wish happi soon compani sha...\n",
      "5553                                hahaha..us brain dear\n",
      "5554    well keep mind i'v got enough ga one round tri...\n",
      "5555    yeh. indian nice. tho kane bit he. shud go 4 d...\n",
      "5556           ye have. that' u texted. pshew...miss much\n",
      "5557    no. meant calcul same. &lt;#&gt; unit &lt;#&gt...\n",
      "5558                               sorry, i'll call later\n",
      "5559                   next &lt;#&gt; hour imma flip shit\n",
      "5560                               anyth lor. juz us lor.\n",
      "5561         get dump heap. mom decid come lowes. boring.\n",
      "5562    ok lor... soni ericsson salesman... ask shuhui...\n",
      "5563                                  ard 6 like dat lor.\n",
      "5564                  wait 'til least wednesday see get .\n",
      "5565                                           huh lei...\n",
      "5566    remind o2: get 2.50 pound free call credit det...\n",
      "5567    2nd time tri 2 contact u. u å£750 pound prize....\n",
      "5568                            ì_ b go esplanad fr home?\n",
      "5569             pity, * mood that. so...ani suggestions?\n",
      "5570    guy bitch act like i'd interest buy someth els...\n",
      "5571                                      rofl. true name\n",
      "Name: v2, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(text):\n",
    "    txt=str(text)\n",
    "    txt=\" \".join([i.lower() for i in txt.split()])\n",
    "    \n",
    "    stops=set(stopwords.words(\"english\"))\n",
    "    txt=\" \".join([w for w in txt.split() if w not in stops])\n",
    "  \n",
    "    stemmer=PorterStemmer()\n",
    "    txt=\" \".join([stemmer.stem(w) for w in txt.split()])\n",
    "    \n",
    "    return txt\n",
    "\n",
    "df['v2']=df['v2'].map(lambda x:preprocess_data(x))\n",
    "print(df['v2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [3399  501]\n",
      "0.12846153846153846\n",
      "0.12846153846153846\n"
     ]
    }
   ],
   "source": [
    "##collecting info from data\n",
    "x_train,x_test,y_train,y_test=train_test_split(df.v2,df.LABEL,random_state=50,test_size=0.3)\n",
    "label,freq=np.unique(y_train,return_counts=True)\n",
    "print(label,freq)\n",
    "prob_spam=freq[1]/(freq[0]+freq[1])\n",
    "prob_ham=freq[0]/(freq[0]+freq[1])\n",
    "print(prob_spam)\n",
    "print(prob_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dictionary for ham and spam containing frequencies for words\n",
    "dic_ham={}\n",
    "dic_spam={}\n",
    "for i in range(0,len(x_train)):\n",
    "    if(np.array(y_train)[i]==0):\n",
    "        for w in np.array(x_train)[i].split():\n",
    "            if w not in dic_ham:\n",
    "                dic_ham[w]=1\n",
    "            else:\n",
    "                dic_ham[w]=dic_ham[w]+1\n",
    "    else:\n",
    "        for w in np.array(x_train)[i].split():\n",
    "            if w not in dic_spam:\n",
    "                dic_spam[w]=1\n",
    "            else:\n",
    "                dic_spam[w]=dic_spam[w]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_unique_words=len(dic_spam)+len(dic_ham)\n",
    "total_spam_words=0\n",
    "total_ham_words=0\n",
    "for i in dic_spam.values():\n",
    "    total_spam_words=total_spam_words+i\n",
    "for i in dic_ham.values():\n",
    "    total_ham_words=total_ham_words+i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(0,len(x_test)):\n",
    "    sum1=np.log(prob_ham)\n",
    "    sum2=np.log(prob_spam)\n",
    "    for w in np.array(x_test)[i].split():\n",
    "        if w in dic_ham:\n",
    "            temp=np.log((dic_ham[w]+1)/(total_ham_words+total_unique_words))\n",
    "        else:\n",
    "            temp=np.log(1/(total_ham_words+total_unique_words))\n",
    "        sum1=sum1+temp\n",
    "        if w in dic_spam:\n",
    "            temp=np.log((dic_spam[w]+1)/(total_spam_words+total_unique_words))\n",
    "        else:\n",
    "            temp=np.log(1/(total_spam_words+total_unique_words))\n",
    "        sum2=sum2+temp\n",
    "    if(sum1 > sum2):\n",
    "        result=0\n",
    "    else:\n",
    "        result=1\n",
    "    if(np.array(y_test)[i]==result):\n",
    "        count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predictions out of 1672 is : 1614\n",
      "Accuracy acheived : 96.5311004784689\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct predictions out of\",len(y_test),\"is :\",count)\n",
    "print(\"Accuracy acheived :\",count/len(y_test)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
